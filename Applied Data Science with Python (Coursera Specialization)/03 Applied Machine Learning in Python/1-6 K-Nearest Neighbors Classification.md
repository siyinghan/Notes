# 1-6 K-Nearest Neighbors Classification

Now that we've gotten a sense for what's in our data set, as a simple example to get started, we're going to use this data set to train a **classifier** that will automatically identify any future pieces of fruit that might come our way. Based on the features available to the classifier such as the object's color, size and mass. To do this, we'll use a popular and easy to understand type of machine learning algorithm known as **k-nearest neighbors** or **k-NN**. *The K-Nearest Neighbors algorithm can be used for* **classification** *and* **regression**. Though, here we'll focus for the time being on using it for classification. **k-NN classifiers** are an example of what's called *instance based or memory based supervised learning*. What this means is that instance based learning methods work by memorizing the labeled examples that they see in the training set. And then they use those memorized examples to classify new objects later. The **k** in **k-NN** refers to **the number of nearest neighbors** the classifier will retrieve and use in order to make its prediction.

